{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e8b21a-d064-43bb-a313-1a0817ed2736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from datasetRegression import DataSetRegression\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1925fc-0605-4ad4-885c-606a266e7394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Hdata(DataSetRegression):\n",
    "    def log_y(self):\n",
    "        self.y = np.log(self.y)\n",
    "        self.mean = self.y.mean()\n",
    "        self.std = self.y.std()\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "    \n",
    "    def unlog_y(self):\n",
    "        self.y = self.y*self.std + self.mean\n",
    "        self.y = np.e**self.y\n",
    "        \n",
    "    def write_answers(self, out_file, predicted):\n",
    "        predicted = predicted*self.std + self.mean\n",
    "        predicted = np.e**predicted\n",
    "        answers = pd.read_csv('HAnswers.csv')\n",
    "        answers['SalePrice'] = predicted\n",
    "        answers.to_csv(f'{out_file}.csv', index=False)\n",
    "    \n",
    "    def predict(self, Model, params, n_splits=5):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=40)\n",
    "        errors = []\n",
    "        self.models = []\n",
    "        for train, test in kf.split(self.all_train_data):\n",
    "            model = Model(**params)\n",
    "            model.fit(self.all_train_data.iloc[train], self.y.iloc[train])\n",
    "            self.models.append(model.copy())\n",
    "            y_pred = model.predict(self.all_train_data.iloc[test])\n",
    "            error = mean_squared_error(y_pred*self.std + self.mean, self.y.iloc[test]*self.std + self.mean, squared=False)\n",
    "            print('{:5.3f}'.format(error))\n",
    "            errors.append(error)\n",
    "        print('total: {:5.3f}'.format(np.mean(errors)))\n",
    "\n",
    "class DjStacking:  \n",
    "    \"\"\"Стэкинг моделей scikit-learn\"\"\"\n",
    "\n",
    "    def __init__(self, models, ens_model):\n",
    "        \"\"\"\n",
    "        Инициализация\n",
    "        models - базовые модели для стекинга\n",
    "        ens_model - мета-модель\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.ens_model = ens_model\n",
    "        self.n = len(models)\n",
    "        self.valid = None\n",
    "        \n",
    "    def fit(self, X, y=None, p=0.1, cv=3, err=0.001, random_state=None):\n",
    "        \"\"\"\n",
    "        Обучение стекинга\n",
    "        p - в каком отношении делить на обучение / тест\n",
    "            если p = 0 - используем всё обучение!\n",
    "        cv  (при p=0) - сколько фолдов использовать\n",
    "        err (при p=0) - величина случайной добавки к метапризнакам\n",
    "        random_state - инициализация генератора\n",
    "            \n",
    "        \"\"\"\n",
    "        if (p > 0): # делим на обучение и тест\n",
    "            # разбиение на обучение моделей и метамодели\n",
    "            train, valid, y_train, y_valid = train_test_split(X, y, test_size=p, random_state=random_state)\n",
    "            \n",
    "            # заполнение матрицы для обучения метамодели\n",
    "            self.valid = np.zeros((valid.shape[0], self.n))\n",
    "            for t, clf in enumerate(self.models):\n",
    "                clf.fit(train, y_train)\n",
    "                self.valid[:, t] = clf.predict(valid)\n",
    "                \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y_valid)\n",
    "            \n",
    "        else: # используем всё обучение\n",
    "            \n",
    "            # для регуляризации - берём случайные добавки\n",
    "            self.valid = err*np.random.randn(X.shape[0], self.n)\n",
    "            \n",
    "            for t, clf in enumerate(self.models):\n",
    "                # это oob-ответы алгоритмов\n",
    "                self.valid[:, t] += cross_val_predict(clf, X, y, cv=cv, n_jobs=-1, method='predict')\n",
    "                # но сам алгоритм надо настроить\n",
    "                clf.fit(X, y)\n",
    "            \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y)  \n",
    "            \n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Работа стэкинга\n",
    "        \"\"\"\n",
    "        # заполение матрицы для мета-классификатора\n",
    "        X_meta = np.zeros((X.shape[0], self.n))\n",
    "        \n",
    "        for t, clf in enumerate(self.models):\n",
    "            X_meta[:, t] = clf.predict(X)\n",
    "        \n",
    "        a = self.ens_model.predict(X_meta)\n",
    "        \n",
    "        return (a)\n",
    "        \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx, :], self.y[idx]\n",
    "        \n",
    "train_data = pd.read_csv('Htrain.csv')\n",
    "test_data = pd.read_csv('Htest.csv')\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "\n",
    "y = train_data.SalePrice\n",
    "X = all_data.drop(columns=['Id', 'SalePrice'])\n",
    "dataset = Hdata(X, y)\n",
    "dataset.X['GarageYrBlt'] = dataset.X['GarageYrBlt'].fillna(dataset.X.loc[dataset.X.GarageYrBlt.isnull()].YearBuilt)\n",
    "na2no = ['MasVnrType', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'BsmtExposure', 'BsmtCond', 'FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "na2mode = ['KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'Electrical', 'Functional', 'Utilities', 'MSZoning']\n",
    "na2zero = ['BsmtFinSF2', 'BsmtFinSF1', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'BsmtUnfSF', 'BsmtHalfBath', 'BsmtFullBath', 'MasVnrArea', 'LotFrontage']\n",
    "dataset.X[na2no] = dataset.X[na2no].fillna('No') # Nan = no this feature\n",
    "dataset.X[na2zero] = dataset.X[na2zero].fillna(0)\n",
    "dataset.X.loc[dataset.X.GarageYrBlt > 2010, ['GarageYrBlt']] = 2010\n",
    "dataset.fill_na_mode(na2mode)\n",
    "dataset.log_y()\n",
    "dataset.ordinal_encoder(dataset.X.select_dtypes('object').columns)\n",
    "dataset.standart_scale(dataset.X.select_dtypes(np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d0887d-8746-4a92-aaff-cb668af11f27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17860/1927846831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mSimpleNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModelBaseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'models'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ens_model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mElasticNetCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17860/3931165409.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, Model, params, n_splits)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_train_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params0 = {'n_estimators': 4096,\n",
    "'max_depth': 3,\n",
    "'eta': 0.05,\n",
    "'subsample': 0.7,\n",
    "'colsample_bytree': 0.8,\n",
    "'lambda': 1,\n",
    "'alpha': 1,\n",
    "'random_state': 42,\n",
    "'tree_method': 'gpu_hist'}\n",
    "\n",
    "models = [SimpleNN(ModelBaseline(), n_epoch=100), XGBRegressor(**params0)]\n",
    "par = {'models' : models, 'ens_model': ElasticNetCV()}\n",
    "dataset.predict(XGBRegressor, params0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c430b6-494f-4858-84f2-f926ebfc17a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104\n",
      "0.130\n",
      "0.116\n",
      "0.129\n",
      "0.135\n",
      "0.261\n",
      "0.123\n",
      "0.144\n",
      "0.138\n",
      "0.123\n",
      "total: 0.140\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model, optimizer=(optim.SGD, {'lr': 1e-3, 'momentum': 0.9}), n_epoch=100, loss=nn.MSELoss(), device='cuda', batch_size=128, dataloader=DataLoader, dataset=Dataset):\n",
    "        self.model = model()\n",
    "        self.model.to(device)\n",
    "        self.n_epoch = n_epoch\n",
    "        self.device = device\n",
    "        self.loss = loss\n",
    "        self.train_dataloader = None\n",
    "        self.batch_size = batch_size\n",
    "        self.dataloader = dataloader\n",
    "        self.dataset = dataset\n",
    "        self.optimizer = optimizer[0](self.model.parameters(), **optimizer[1])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        y = torch.tensor(y.values, dtype=torch.float32)\n",
    "        data = self.dataset(X, y)\n",
    "        self.train_dataloader = self.dataloader(data, batch_size=self.batch_size, shuffle=True)\n",
    "        for i in range(self.n_epoch):\n",
    "            self.train_one_epoch()\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        for x, y in self.train_dataloader:\n",
    "            y = torch.unsqueeze(y, 1)\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.to(self.device)\n",
    "        X = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "        self.y_pred = self.model(X).cpu().detach().numpy().flatten()\n",
    "        return self.y_pred\n",
    "    \n",
    "    def score(self, y_true):\n",
    "        label = y_true.values\n",
    "        return nn.MSELoss()(torch.tensor(self.y_pred), torch.tensor(y_true)).numpy(), np.corrcoef(self.y_pred, label)[0, 1]\n",
    "    \n",
    "    def copy(self):\n",
    "        return deepcopy(self)\n",
    "\n",
    "class ModelBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBaseline, self).__init__()\n",
    "        self.full1 = nn.Linear(79, 64)\n",
    "        self.full2 = nn.Linear(64, 32)\n",
    "        # self.full3 = nn.Linear(32, 8)\n",
    "        # self.full4 = nn.Linear(8, 4)\n",
    "        self.full5 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.full1(x))\n",
    "        out = F.leaky_relu(self.full2(out)) \n",
    "        # out = F.leaky_relu(self.full3(out))\n",
    "        # out = F.leaky_relu(self.full4(out)) \n",
    "        out = self.full5(out)\n",
    "        return out\n",
    "\n",
    "dataset.predict(SimpleNN, {'model': ModelBaseline, 'n_epoch': 100}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b2519f0-78bf-4c4a-b2cd-063ff305233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "a = np.array([0.104,0.130,0.116,0.129,0.135,0.261,0.123,0.144,0.138,0.123])**-1\n",
    "a = a/np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87373f0e-6dc6-4295-b06b-ef94389c392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt, model in enumerate(dataset.models):\n",
    "    predicted.append(model.predict(dataset.submission_data)[:, np.newaxis] * a[cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc31110-2845-4500-a0ec-4c3c374a53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.write_answers('nn10', np.sum(predicted, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
