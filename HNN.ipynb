{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a98387-55e6-4ccf-993b-fb6cc1a16d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgrammFiles\\Anaconda\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class DataSetRegression():\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y\n",
    "        self.X_transform = pd.DataFrame([])\n",
    "        self.standart_scaler = StandardScaler()\n",
    "        self.data = pd.concat([self.X, self.y], axis=1)\n",
    "        self.ordEnc = OrdinalEncoder()\n",
    "        \n",
    "    def showMissData(self):\n",
    "        miss_data = self.X.isnull().sum().sort_values()\n",
    "        miss_data[miss_data > 0].plot.bar(color='green')\n",
    "        return miss_data[miss_data > 0].index\n",
    "        \n",
    "    def fillNaMode(self, columns):\n",
    "        for i in columns:\n",
    "            self.X[i] = self.X[i].fillna(self.X[i].mode()[0])\n",
    "            \n",
    "    def ohe(self, columns, drop_first=True):\n",
    "        self.X[columns] = self.X[columns].astype('str')\n",
    "        self.X_transform = pd.concat([pd.get_dummies(self.X[columns], drop_first=drop_first), self.X_transform], axis=1)\n",
    "        \n",
    "    def notScale(self, columns):\n",
    "        self.X_transform = pd.concat([self.X[columns], self.X_transform], axis=1)\n",
    "    \n",
    "    def standartSc(self, columns):\n",
    "        sk = pd.DataFrame(self.standart_scaler.fit_transform(self.X[columns]), columns=columns)\n",
    "        self.X_transform = pd.concat([sk, self.X_transform], axis=1)\n",
    "    \n",
    "    def train_test_split(self, *args, **kwargs):\n",
    "        return train_test_split(self.X_transform[:len(self.y)], self.y, *args, **kwargs)\n",
    "    \n",
    "    def pred_data(self):\n",
    "        return self.X_transform[len(self.y):]\n",
    "    \n",
    "    def all_train_data(self):\n",
    "        return self.X_transform[:len(self.y)]\n",
    "    \n",
    "    def ordinalEnc(self, columns):\n",
    "        self.X[columns] = self.X[columns].astype('str')\n",
    "        gg = self.ordEnc.fit_transform(self.X[columns])\n",
    "        oe = pd.DataFrame(gg, columns=columns)\n",
    "        self.X_transform = pd.concat([self.X_transform, oe], axis=1)\n",
    "    \n",
    "    def corrMatrix(self, n2show=25):\n",
    "        corrM = self.data.corr()\n",
    "        fig, ax = plt.subplots(dpi = 150, figsize=(10, 8))\n",
    "        cols = corrM.nlargest(n2show, self.y.name)[self.y.name].index\n",
    "        sns.heatmap(corrM.loc[cols, cols], annot=True, cmap=\"YlGnBu\", linewidths=0.1,)\n",
    "        return cols\n",
    "    \n",
    "    def quant(self, col='label', q=0.99):\n",
    "        if col == 'label':\n",
    "            quant = np.quantile(self.y, 0.99)\n",
    "            self.y[self.y > quant] = quant\n",
    "        else:\n",
    "            quant = np.quantile(self.X[col], q)\n",
    "            # print('{:15s} {:10.3e}'.format(col, quant))\n",
    "            self.X.loc[self.X[col] > quant, col] = quant\n",
    "            \n",
    "    def showq_quant(self, col):\n",
    "        d = pd.DataFrame.quantile(self.X[col], [0.0, 0.25, 0.5, 0.75, 1])\n",
    "        d = d - d.iloc[2]\n",
    "        d = d.append(d.iloc[0]/d.iloc[1], ignore_index=True)\n",
    "        d = d.append(d.iloc[4]/d.iloc[3], ignore_index=True)\n",
    "        d = d.set_index(pd.Index(['0%', '25%', '50%', '75%', '100%', '0/25', '1/75']))\n",
    "        d = d.replace([np.inf, -np.inf], np.nan)\n",
    "        return d.dropna(axis=1)\n",
    "\n",
    "from sklearn.linear_model import LassoCV,  BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "class HoueseData(DataSetRegression):\n",
    "    def predict(self, models, params):\n",
    "        X = self.all_train_data()\n",
    "        kf = KFold(n_splits=10)\n",
    "        self.ensemble = []\n",
    "        errors = np.array([])\n",
    "        for cnt, model in enumerate(models):\n",
    "            for train, test in kf.split(X):\n",
    "                if cnt == 0:\n",
    "                    m = model(**params)\n",
    "                else:\n",
    "                    m = model()\n",
    "                m.fit(X.iloc[train], y.iloc[train])\n",
    "                self.ensemble.append(m)\n",
    "                y_pred = m.predict(X.iloc[test])\n",
    "                error = mean_squared_error(np.log(y_pred), np.log(y.iloc[test]), squared=False)\n",
    "                errors = np.append(errors, error)\n",
    "            print('{:5.3f}'.format(errors.mean()))\n",
    "        print('Total: {:5.3f}'.format(errors.mean()))\n",
    "    \n",
    "    def scaleLabel(self):\n",
    "        self.y = np.log(self.y)\n",
    "        self.mean = dataset.y.mean()\n",
    "        self.std = dataset.y.std()\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "    def labelBack(self):\n",
    "        self.y = self.y*self.std + self.mean\n",
    "        self.y = np.e**self.y\n",
    "    \n",
    "train_data = pd.read_csv('Htrain.csv')\n",
    "test_data = pd.read_csv('Htest.csv')\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "                \n",
    "y = train_data.SalePrice\n",
    "\n",
    "X = all_data.drop(columns=['Id', 'SalePrice'])\n",
    "dataset = HoueseData(X, y)\n",
    "\n",
    "\n",
    "dataset.X['GarageYrBlt'] = dataset.X['GarageYrBlt'].fillna(dataset.X.loc[dataset.X.GarageYrBlt.isnull()].YearBuilt)\n",
    "dataset.X = dataset.X.fillna(0)\n",
    "cols2cut = ['LotArea', 'MasVnrArea', 'TotalBsmtSF', '2ndFlrSF', 'LowQualFinSF', 'GarageYrBlt', 'label']\n",
    "for i in cols2cut:\n",
    "    q = 0.99\n",
    "    dataset.quant(i, q)\n",
    "na2no = ['MasVnrType', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'BsmtExposure', 'BsmtCond', 'FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "na2mode = ['KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'Electrical', 'Functional', 'Utilities', 'MSZoning']\n",
    "dataset.X[na2no] = dataset.X[na2no].fillna('No') # Nan = no this feature\n",
    "dataset.fillNaMode(na2mode)    \n",
    "\n",
    "dataset.ordinalEnc(dataset.X.select_dtypes('object').columns)\n",
    "dataset.standartSc(dataset.X.select_dtypes(np.number).columns)\n",
    "dataset.scaleLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06dd5609-449e-4ad9-b000-52b5bf5e7163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:     0, loss: 0.100, coerr: 0.918\n",
      "model:     1, loss: 0.076, coerr: 0.955\n",
      "model:     2, loss: 0.072, coerr: 0.969\n",
      "model:     3, loss: 0.126, coerr: 0.944\n",
      "model:     4, loss: 0.150, coerr: 0.922\n",
      "model:     5, loss: 0.089, coerr: 0.953\n",
      "model:     6, loss: 0.075, coerr: 0.958\n",
      "model:     7, loss: 0.094, coerr: 0.933\n",
      "model:     8, loss: 0.345, coerr: 0.808\n",
      "model:     9, loss: 0.107, coerr: 0.945\n",
      "Total loss: 0.124\n"
     ]
    }
   ],
   "source": [
    "n_splits=10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx, :], self.y[idx]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class ModelBaseline(nn.Module):\n",
    "    def __init__(self, n_feature=78, n_hidden=64, n_output=1):\n",
    "        super(ModelBaseline, self).__init__()\n",
    "        self.full1 = nn.Linear(79, 64)\n",
    "        self.full2 = nn.Linear(64, 32)\n",
    "        # self.full3 = nn.Linear(32, 8)\n",
    "        # self.full4 = nn.Linear(8, 2)\n",
    "        self.full5 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.full1(x))\n",
    "        out = F.leaky_relu(self.full2(out))\n",
    "        # out = F.leaky_relu(self.full3(out))\n",
    "        # out = F.leaky_relu(self.full4(out))        \n",
    "        out = self.full5(out)\n",
    "        return out\n",
    "    \n",
    "X = dataset.all_train_data()\n",
    "label = dataset.y\n",
    "def checkpoint(model, path):\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, f'{path}.pt')\n",
    "n = 0\n",
    "total_loss = []\n",
    "n_epoch = 50\n",
    "with tqdm(total=n_splits, file=sys.stdout, leave=False) as prbar:\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = torch.tensor(X.iloc[train].values, dtype=torch.float32)\n",
    "        X_test = torch.tensor(X.iloc[test].values, dtype=torch.float32)\n",
    "        y_train = torch.tensor(label.iloc[train].values, dtype=torch.float32)\n",
    "        y_test = torch.tensor(label.iloc[test].values, dtype=torch.float32)\n",
    "\n",
    "        training_data = Dataset(X_train, y_train)\n",
    "        test_data = Dataset(X_test, y_test)\n",
    "        bs = 128\n",
    "        train_dataloader = DataLoader(training_data, batch_size=bs, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "\n",
    "        model = ModelBaseline(79, 64, 1).to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            model.train()\n",
    "            for x, y in train_dataloader:\n",
    "                y = torch.unsqueeze(y, 1)\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x)\n",
    "                loss = nn.MSELoss()(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model.eval()    \n",
    "            mean_val_loss = []\n",
    "            mean_val_coerr = []\n",
    "            if (epoch+1)%n_epoch==0:\n",
    "                with torch.no_grad():\n",
    "                    for x_val, y_val in test_dataloader:\n",
    "                        y_val = torch.unsqueeze(y_val, 1)\n",
    "                        x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                        y_pred = model(x_val)\n",
    "                        loss1 = np.corrcoef(y_pred.cpu().detach().numpy().flatten(), y_val.cpu().flatten())[0, 1]\n",
    "                        y_pred = y_pred\n",
    "                        y_val = y_val\n",
    "                        loss2 = nn.MSELoss()(y_pred, y_val).cpu().detach().numpy()\n",
    "                        mean_val_loss.append(loss2) #.cpu().detach().numpy()\n",
    "                        mean_val_coerr.append(loss1)\n",
    "                print('model: {:5d}, loss: {:.3f}, coerr: {:.3f}'.format(n, np.mean(mean_val_loss), np.mean(mean_val_coerr)))\n",
    "        total_loss.append(np.mean(mean_val_loss))        \n",
    "        checkpoint(model, f'models/{n}')\n",
    "        prbar.update(1)\n",
    "        n+=1\n",
    "print('Total loss: {:.3f}'.format(np.mean(total_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cb2de39-cf02-485e-986a-bcd2d321ff5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d51ee475967448d9ed59dbedbadb88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:    0.101, coerr:    0.946\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, model, optimizer=(optim.SGD, {'lr': 1e-3, 'momentum': 0.9}), n_epoch=100, loss=nn.MSELoss(), device='cuda', batch_size=128, dataloader=DataLoader, dataset=Dataset):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.n_epoch = n_epoch\n",
    "        self.device = device\n",
    "        self.loss = loss\n",
    "        self.train_dataloader = None\n",
    "        self.batch_size = batch_size\n",
    "        self.dataloader = dataloader\n",
    "        self.dataset = dataset\n",
    "        self.optimizer = optimizer[0](self.model.parameters(), **optimizer[1])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        y = torch.tensor(y.values, dtype=torch.float32)\n",
    "        data = self.dataset(X, y)\n",
    "        self.train_dataloader = self.dataloader(data, batch_size=bs, shuffle=True)\n",
    "        for i in range(self.n_epoch):\n",
    "            self.train_one_epoch()\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        for x, y in self.train_dataloader:\n",
    "            y = torch.unsqueeze(y, 1)\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "        self.y_pred = self.model(X).cpu().detach().numpy().flatten()\n",
    "        return self.y_pred\n",
    "    \n",
    "    def score(self, y_true):\n",
    "        label = y_true.values\n",
    "        return nn.MSELoss()(torch.tensor(self.y_pred), torch.tensor(y_true)).numpy(), np.corrcoef(self.y_pred, label)[0, 1]\n",
    "    \n",
    "\n",
    "with tqdm(total=n_splits, file=sys.stdout, leave=False) as prbar:\n",
    "    for train, test in kf.split(X):\n",
    "        model = SimpleNN(ModelBaseline(79, 64, 1), n_epoch=100)\n",
    "        model.fit(X.iloc[train], label.iloc[train])\n",
    "        y_pred = model.predict(X.iloc[test])\n",
    "        print( 'loss: {:8.3f}, coerr: {:8.3f}'.format(*model.score(label.iloc[test])) )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218aadd1-ac22-4d08-868d-a021a7c9034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(10):\n",
    "    model = ModelBaseline(79, 64, 1).to(device)\n",
    "    chk = torch.load(f'models/{i}.pt')\n",
    "    model.load_state_dict(chk['model_state_dict'])\n",
    "    y_pred = model(torch.tensor(dataset.X_transform.values, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "    preds.append(y_pred)\n",
    "\n",
    "features = np.hstack(preds)\n",
    "\n",
    "features  = np.e**(features*dataset.std + dataset.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2544542-cb00-4996-ad93-fae4d7547cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HoueseData(pd.DataFrame(features), train_data.SalePrice)\n",
    "dataset.notScale(dataset.X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc22be9f-99a8-43db-810e-01a981ce0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X_transform.to_csv('000NNFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4541878-984a-428e-bf53-a3e6a4725e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17095.184861103877\n"
     ]
    }
   ],
   "source": [
    "n_splits=10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "total_error = []\n",
    "for train, test in kf.split(dataset.all_train_data()):\n",
    "    model = Lasso(alpha=1)\n",
    "    model.fit(dataset.all_train_data().iloc[train].values, dataset.y.iloc[train].values)\n",
    "    y_pred = model.predict(dataset.all_train_data().iloc[test].values)\n",
    "    total_error.append(mean_squared_error(y_pred, dataset.y.iloc[test].values, squared=False))\n",
    "print(np.mean(total_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de11c05-c341-44f5-ae65-249bed031f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = dataset.train_test_split(test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2a23a6b-f17d-4248-ae95-2ee5b5d50d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lasso()\n",
    "model.fit(dataset.all_train_data(), dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "359d811e-bdf0-4f76-8e0a-7437fe878e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(dataset.pred_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b6d86ea-0a3d-4bba-bf39-bc2e9442cf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers = pd.read_csv('HAnswers.csv')\n",
    "answers['SalePrice'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f22a1f3f-571f-4a91-9c7f-8454de41c57e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers.to_csv('NNensembleAnswers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6eb6a041-f2f8-4ff8-8209-73f3b651d524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>116483.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>143369.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>176476.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>194437.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>184371.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>94270.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>79970.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>171321.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>121432.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>238613.828125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  116483.054688\n",
       "1     1462  143369.468750\n",
       "2     1463  176476.687500\n",
       "3     1464  194437.828125\n",
       "4     1465  184371.546875\n",
       "...    ...            ...\n",
       "1454  2915   94270.500000\n",
       "1455  2916   79970.484375\n",
       "1456  2917  171321.687500\n",
       "1457  2918  121432.015625\n",
       "1458  2919  238613.828125\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b545d-1fc1-495f-a7da-147a2dca2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('HAnswers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
